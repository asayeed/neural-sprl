import array
import io
import numpy as np

def load_stanford(filename, num_special=0):
  """
  Method modified from:
    https://github.com/maciejkula/glove-python/blob/master/glove/glove.py
  Load model from the output files generated by
  the C code from http://nlp.stanford.edu/projects/glove/.
  The entries of the word dictionary will be of type
  unicode in Python 2 and str in Python 3.
  """

  wtoi = {}
  itow = num_special*[u'_SPECIAL']
  vectors = array.array('d')

  # Read in the data.
  with io.open(filename, 'r', encoding='utf-8') as savefile:
    for i, line in enumerate(savefile, num_special):
      tokens = line.split(' ')

      word = tokens[0]
      entries = tokens[1:]

      wtoi[word] = i
      itow.append(word)
      vectors.extend(float(x) for x in entries)

  # Infer word vectors dimensions.
  no_components = len(entries)
  no_vectors = len(wtoi)

  # Set up the model instance.
  no_components = no_components
  word_vectors = (np.array(vectors)
                           .reshape(no_vectors,
                                    no_components))

  return wtoi, itow, word_vectors

def load_supersenses(filename):
  """
  Loads a file with a list of all 26 WordNet noun supersenses.
  Returns:
    stoi : A mapping from supersense name (str) to integer id.
    itos : A list of supersense names (str), indices is integer id.
  """
  stoi = {}
  itos = []
  with io.open(filename, 'r') as fp:
    for i, line in enumerate(fp):
      line = line.strip()
      assert line.startswith("noun")
      assert len(line.split()) == 1
      itos.append(line)
      stoi[line] = i
  assert len(itos) == 26
  return stoi, itos

